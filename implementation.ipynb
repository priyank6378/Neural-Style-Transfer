{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 200\n",
    "img_width = 400\n",
    "original_img_height = 200\n",
    "original_img_width = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    global original_img_height, original_img_width\n",
    "    original_img_height, original_img_width = img.shape[0], img.shape[1]\n",
    "    img = cv2.resize(img, (img_width, img_height))\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = keras.applications.vgg19.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def deprocess_image(img):\n",
    "    img = cv2.resize(img, (original_img_width, original_img_height))\n",
    "    # Remove zero-center by mean pixel\n",
    "    img[:, :, 0] += 103.939\n",
    "    img[:, :, 1] += 116.779\n",
    "    img[:, :, 2] += 123.68\n",
    "    # BGR to RGB\n",
    "    img = img[:, :, ::-1]\n",
    "    img = np.clip(img, 0, 255).astype('uint8')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_loss(P, F):\n",
    "    return 0.5*tf.reduce_sum(tf.square(F - P))\n",
    "\n",
    "def gram_matrix(x):\n",
    "    x = tf.matmul(x, tf.transpose(x))\n",
    "    return x\n",
    "\n",
    "def style_loss(F, G):\n",
    "    gram_F = gram_matrix(F)\n",
    "    gram_G = gram_matrix(G)\n",
    "    return tf.reduce_sum(tf.square(gram_F - gram_G)) / (4. * (F.shape[0] * F.shape[1])**2)\n",
    "\n",
    "def total_variation_loss(x):\n",
    "    a = tf.square(\n",
    "        x[:, : -1, : -1, :] - x[:, 1:, : - 1, :]\n",
    "    )\n",
    "    b = tf.square(\n",
    "        x[:, : -1 , : - 1, :] - x[:, : - 1, 1:, :]\n",
    "    )\n",
    "    return tf.reduce_sum(tf.pow(a+b, 1.25))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = keras.applications.vgg19.VGG19(include_top=False, weights='imagenet')\n",
    "layers_dict = dict([(layer.name, layer.output) for layer in vgg.layers])\n",
    "\n",
    "feature_extractor = keras.Model(vgg.input , layers_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = preprocess_image('target/target.jpg')\n",
    "style = preprocess_image('style/style.jpg')\n",
    "combination = tf.Variable(copy.deepcopy(base))\n",
    "\n",
    "style_layer = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n",
    "content_layer = 'block5_conv2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.Adam(learning_rate=0.1)\n",
    "iterations = 10000\n",
    "alpha = 10\n",
    "beta = 1000\n",
    "gamma = 1e-5\n",
    "\n",
    "for i in range(iterations):\n",
    "    with tf.GradientTape() as tape:\n",
    "        x = feature_extractor(base)\n",
    "        y = feature_extractor(style)\n",
    "        z = feature_extractor(combination)\n",
    "\n",
    "        style_l = tf.zeros(shape=())\n",
    "        content_l = tf.zeros(shape=())\n",
    "\n",
    "        for layer in style_layer:\n",
    "            t = y[layer][0]\n",
    "            t = tf.reshape(tf.transpose(t, (2, 0, 1)), (tf.shape(t)[0], -1))\n",
    "            q = z[layer][0]\n",
    "            q = tf.reshape(tf.transpose(q, (2, 0, 1)), (tf.shape(q)[0], -1))\n",
    "            style_l += style_loss(t, q)\n",
    "        \n",
    "        t = x[content_layer]\n",
    "        t = tf.reshape(t, (t.shape[-1], -1))\n",
    "        q = z[content_layer]\n",
    "        q = tf.reshape(q, (q.shape[-1], -1))\n",
    "        content_l += content_loss(t, q)\n",
    "\n",
    "        variation_l = tf.zeros(shape=())\n",
    "        variation_l = total_variation_loss(combination)\n",
    "\n",
    "        total_loss = alpha*content_l + beta*style_l/len(style_layer) + gamma*variation_l\n",
    "\n",
    "    grads = tape.gradient(total_loss, combination)\n",
    "    optimizer.apply_gradients([(grads, combination)])\n",
    "\n",
    "    if i % 500 == 0:\n",
    "        print(\"Iteration: {}  Loss = {}\".format(i, total_loss))\n",
    "        img = deprocess_image(np.array(combination[0][:,:,::-1]))\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = deprocess_image(np.array(combination[0][:,:,::-1]))\n",
    "keras.utils.save_img(f\"combination/combination_image2.jpg\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
